Pacf(foo)$acf
model <- Arima(ts(rnorm(100),freq=12), order=c(0,0,1), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100),freq=12), order=c(0,0,0), seasonal=c(0,0,1))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100),freq=12), order=c(1,0,0), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100),freq=12), order=c(0,0,1), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100)+25,freq=12), order=c(0,0,1), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100,0,0.01),freq=12), order=c(0,0,1), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100,0,0.01),freq=12), order=c(1,0,0), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
model <- Arima(ts(rnorm(100,1,0.01),freq=12), order=c(1,0,0), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100,1,0.0001),freq=12), order=c(1,0,0), seasonal=c(0,0,0))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
Pacf(foo)$acf
model <- Arima(ts(rnorm(100,1,0.0001),freq=12), order=c(0,0,0), seasonal=c(0,0,1))
foo <- simulate(model, nsim=200)
Acf(foo)$acf
thepacf=ARMAacf (ar = c(.6,0,0,0,0,0,0,0,0,0,0,.5,-.30),lag.max=30,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,.5),lag.max=30,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,.5),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,-0.5),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(1,0,0,0,0,0,0,0,0,0,0,0),lag.max=90,pacf=T)
thepacf=ARMAacf (ar = c(1),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(1),lag.max=90,acf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(1),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(-1),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = -0.9,lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = -0.9,lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (aq = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,acf=T)
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=F)
plot (thepacf,type="h")
thepacf=ARMAacf (ar = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
thepacf=ARMAacf (ma = c(0,0,0,0,0,0,0,0,0,0,0,-0.9),lag.max=90,pacf=T)
plot (thepacf,type="h")
library(tm)
library(SnowballC)
library(dplyr)
pres_stats <- data.frame(
row.names = c("Democrat", "Barrack Obama", "William Clinton", "Republican", "George W. Bush", "Donald Trump"),
Words = c(53165, 26502, 26663, 53080, 26063, 27017))
knitr::kable(pres_stats,booktabs = T)
clean_corp <- function(corp) {
corp %>%
tm_map(tolower) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace) %>%
tm_map(removeWords, c(stopwords("english"), "president", "applause", "will"))
}
library(tm)
library(SnowballC)
library(dplyr)
pres_stats <- data.frame(
row.names = c("Democrat", "Barrack Obama", "William Clinton", "Republican", "George W. Bush", "Donald Trump"),
Words = c(53165, 26502, 26663, 53080, 26063, 27017))
knitr::kable(pres_stats,booktabs = T)
clean_corp <- function(corp) {
corp %>%
tm_map(tolower) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace) %>%
tm_map(removeWords, c(stopwords("english"), "president", "applause", "will"))
}
Trump
J="a b c d e f g h i"
con_corp <- Corpus(DirSource("/Users/mukeshravichandran/Downloads/Mukesh_proj"), readerControl = list(language="lat"))
con_corp <- clean_corp(con_corp)
wordcloud(con_corp, random.order=FALSE, scale=c(3, .5), use.r.layout=TRUE,colors = brewer.pal(5, "Dark2"), max.words=75)
install.packages("wordcloud")
library(wordcloud)
wordcloud(con_corp, random.order=FALSE, scale=c(3, .5), use.r.layout=TRUE,colors = brewer.pal(5, "Dark2"), max.words=75)
con_tdm <- TermDocumentMatrix(con_corp)
con_m <- as.matrix(con_tdm)
con_df <- data.frame(word = row.names(con_m), con_m)
con_df$word <- as.character(con_df$word)
colnames(con_df) <- c("word", "count")
con_df %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% summarize(sent_ttl = sum(count))
library(dplyr)
con_df %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% summarize(sent_ttl = sum(count))
library(tidy)
install.packages("tidy")
install.packages("get_sentiments")
rm(list = ls())
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(ggplot2)
library(lubridate)
library(gtable)
library(dplyr)
library(MLmetrics)
library(stinepack)
library(data.table)
library(imputeTS)
library(gridExtra)
setwd("/Users/mukeshravichandran/OneDrive - North Carolina State University/MSA-Mukesh’s MacBook Pro/Courses/Fall/AA502/Fall 1/Time Series/Project/Data")
my_theme = theme_minimal()+theme(plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill='white')) + theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
#Reading all the project files in
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
#white noise plot
white.noise = function(df) {
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(df, lag = i, type = "Lj", fitdf = 1)$p.value
}
White.LBred <- pmin(White.LB, 0.2)
barplot(White.LBred, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
return(White.LB)
}
#Reading all the project files in
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
setwd("/Users/mukeshravichandran/OneDrive - North Carolina State University/MSA-Mukesh’s MacBook Pro/Courses/Fall/AA502/Fall 1/Time Series/Project/Data")
setwd("/Users/mukeshravichandran/OneDrive - North Carolina State University/MSA-Mukesh’s MacBook Pro/Courses/Fall/AA502/Fall 1/Time Series/Project/Code/Ozone_Prediction/Data")
my_theme = theme_minimal()+theme(plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill='white')) + theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
#Reading all the project files in
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
#white noise plot
white.noise = function(df) {
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(df, lag = i, type = "Lj", fitdf = 1)$p.value
}
White.LBred <- pmin(White.LB, 0.2)
barplot(White.LBred, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
return(White.LB)
}
adf= function(series) {
ADF.Pvalues <- rep(NA, 3)
for(i in 0:2){
ADF.Pvalues[i+1] <- adf.test(series, alternative = "stationary", k = i)$p.value
}
ADF.Pvalues
}
ozone = select(Ozone_Raleigh2.csv,c("Date", "Daily.Max.8.hour.Ozone.Concentration"))
ozone$Date = mdy(ozone$Date)
#Converting in to Date time and imputing missing values
Date <- seq(min(ozone$Date), max(ozone$Date), by = 1)
Date= as.data.frame(Date)
ozone= full_join(Date,ozone,by="Date", suffix=c("",""))
sum(is.na(ozone$Daily.Max.8.hour.Ozone.Concentration)) #60 values missing
ozone$Daily.Max.8.hour.Ozone.Concentration= na_interpolation(ozone$Daily.Max.8.hour.Ozone.Concentration,option = "spline")
sum(is.na(ozone$Daily.Max.8.hour.Ozone.Concentration)) #no values missing
#converting in to time series
ozone_ts= ts(ozone$Daily.Max.8.hour.Ozone.Concentration,start= 2014,frequency = 365.25)
plot1= autoplot(ozone_ts, color= "blue")+my_theme
training= subset(ozone_ts,end=length(ozone_ts)-(28+14))
validation= subset(ozone_ts,start=length(ozone_ts)-(28+14-1), end=length(ozone_ts)-14)
testing= subset(ozone_ts,start=length(ozone_ts)-(13), end=length(ozone_ts))
autoplot(training)
autoplot(training)+my
autoplot(training)+my_theme
#checking if the split is done properly
length(training)
length(validation)
length(testing)
length(ozone_ts)
sum(ozone_ts == c(training,validation,testing)) == length(ozone_ts)
Trial_1_Seasonal<-Arima(training,order=c(0,0,0),seasonal=c(0,0,0),xreg=fourier(training,K=6))
autoplot(Trial_1_Seasonal$residuals,color="red")+ geom_hline(yintercept=0,linetype="dashed")
adf(Trial_1_Seasonal$residuals) # seems like the residuals are stationary
white.noise(Trial_1_Seasonal$residuals) #--> No white noise, so there is some correlation
Acf(Trial_1_Seasonal$residuals,lag.max = 400)$acf
Pacf(Trial_1_Seasonal$residuals,lag.max = 400)$acf
auto.arima(Trial_1_Seasonal$residuals)
Trial_2_Seasonal<-Arima(training,order=c(2,0,0),seasonal=c(0,0,0),xreg=fourier(training,K=6))
autoplot(Trial_2_Seasonal$residuals,color="red")+ geom_hline(yintercept=0,linetype="dashed") #definitely better than the first one
adf(Trial_2_Seasonal$residuals)
white.noise(Trial_2_Seasonal$residuals) # yaay white noise
summary(Trial_2_Seasonal)
autoplot(forecast(Trial_2_Seasonal,xreg = fourier(training,K=6)[109.5:509.25,])) + my_theme + labs(title = "ARIMA Model", y= "Daily 8 Hour Maximum Ozone Concentration", X= "Date")
#imputing CO missing values
CO = select(CO_Raleigh.csv,c("Date", "Daily.Max.8.hour.CO.Concentration"))
CO$Date = mdy(CO$Date)
Date <- seq(min(CO$Date), max(CO$Date), by = 1)
Date= as.data.frame(Date)
CO= full_join(Date,CO,by="Date", suffix=c("",""))
sum(is.na(CO$Daily.Max.8.hour.CO.Concentration))
CO$Daily.Max.8.hour.CO.Concentration= na_interpolation(CO$Daily.Max.8.hour.CO.Concentration,option = "spline")
CO_ts= ts(CO$Daily.Max.8.hour.CO.Concentration, start = 2014, frequency = 365.25)
plot2= autoplot(CO_ts, color= "black")+my_theme
#imputing SO2 missing values
SO2 = select(SO2_Raleigh.csv,c("Date", "Daily.Max.1.hour.SO2.Concentration"))
SO2$Date = mdy(SO2$Date)
Date <- seq(min(SO2$Date), max(SO2$Date), by = 1)
Date= as.data.frame(Date)
SO2= full_join(Date,SO2,by="Date", suffix=c("",""))
sum(is.na(SO2$Daily.Max.1.hour.SO2.Concentration))
SO2$Daily.Max.1.hour.SO2.Concentration= na_interpolation(SO2$Daily.Max.1.hour.SO2.Concentration,option = "spline")
SO2_ts= ts(SO2$Daily.Max.1.hour.SO2.Concentration, start = 2014, frequency = 365.25)
plot3= autoplot(SO2_ts, color= "green")+my_theme
NO2 = select(NO_Raleigh.csv,c("Date", "Daily.Max.1.hour.NO2.Concentration"))
NO2$Date = mdy(NO2$Date)
Date <- seq(min(NO2$Date), max(NO2$Date), by = 1)
Date= as.data.frame(Date)
NO2= full_join(Date,NO2,by="Date", suffix=c("",""))
sum(is.na(NO2$Daily.Max.1.hour.NO2.Concentration))
NO2$Daily.Max.1.hour.NO2.Concentration= na_interpolation(NO2$Daily.Max.1.hour.NO2.Concentration,option = "spline")
NO2_ts= ts(NO2$Daily.Max.1.hour.NO2.Concentration, start = 2014, frequency = 365.25)
plot4= autoplot(NO2_ts, color= "red")+my_theme
tmax = select(Raleigh_weather.csv,c("DATE", "TMAX"))
tmax$DATE = mdy(tmax$DATE)
DATE <- seq(min(tmax$DATE), max(tmax$DATE), by = 1)
DATE= as.data.frame(DATE)
tmax= full_join(DATE,tmax,by="DATE", suffix=c("",""))
sum(is.na(tmax$TMAX))
tmax$TMAX= na_interpolation(tmax$TMAX,option = "spline")
tmax_ts= ts(tmax$TMAX, start = 2014, frequency = 365.25)
plot5= autoplot(tmax_ts, color= "skyblue")+my_theme
grid.arrange(plot1+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()), plot2+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot3+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot4+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot5, ncol=1)
NO2_Seasonal<-Arima(NO2_ts,order=c(0,0,0),seasonal=c(0,0,0),xreg=fourier(NO2_ts,K=6))
autoplot(NO2_Seasonal$residuals)
adf(NO2_Seasonal$residuals)
white.noise(NO2_Seasonal$residuals)
Acf(NO2_Seasonal$residuals)$acf
Pacf(NO2_Seasonal$residuals,lag.max = 400)$acf
auto.arima(NO2_Seasonal$residuals)
NO2_Seasonal_2<-Arima(NO2_ts,order=c(5,0,0),seasonal=c(0,0,0),xreg=fourier(NO2_ts,K=6))
adf(NO2_Seasonal_2$residuals)
white.noise(NO2_Seasonal_2$residuals)    #yaay white noise
ccf(NO2_Seasonal_2$residuals,Trial_2_Seasonal$residuals,lag.max = 10)
####Arima to model TMAX####
tmax_seasonal<-Arima(tmax_ts,order=c(0,0,0),seasonal=c(0,0,0),xreg=fourier(tmax_ts,K=6))
autoplot(tmax_seasonal$residuals)
adf(tmax_seasonal$residuals)
white.noise(tmax_seasonal$residuals)
Acf(tmax_seasonal$residuals)$acf
Pacf(tmax_seasonal$residuals,lag.max = 400)$acf
auto.arima(tmax_seasonal$residuals)
tmax_seasonal_2<-Arima(tmax_ts,order=c(5,0,0),seasonal=c(0,0,0),xreg=fourier(tmax_ts,K=6))
adf(NO2_Seasonal_2$residuals)
white.noise(NO2_Seasonal_2$residuals)    #yaay white noise
ccf(tmax_seasonal_2$residuals,Trial_2_Seasonal$residuals,lag.max = 10)
CO_seasonal<-Arima(CO_ts,order=c(0,0,0),seasonal=c(0,0,0),xreg=fourier(CO_ts,K=6))
autoplot(CO_seasonal$residuals)
adf(CO_seasonal$residuals)
white.noise(CO_seasonal$residuals)
Acf(CO_seasonal$residuals)$acf
Pacf(CO_seasonal$residuals,lag.max = 400)$acf
CO_seasonal_2<-Arima(CO_ts,order=c(5,0,0),seasonal=c(0,0,0),xreg=fourier(CO_ts,K=6))
adf(CO_seasonal_2$residuals)
white.noise(CO_seasonal_2$residuals)    #yaay white noise
ccf(CO_seasonal_2$residuals,Trial_2_Seasonal$residuals,lag.max = 10)
arimax= Arima(ozone_ts,order=c(0,0,0),seasonal=c(0,0,0),xreg=cbind(fourier(ozone_ts,K=6),tmax_seasonal_2$residuals,NO2_Seasonal_2$residuals))
adf(arimax$residuals)
white.noise(arimax$residuals)
arimax_2= Arima(ozone_ts,order=c(1,0,0),seasonal=c(0,0,0),xreg=cbind(fourier(ozone_ts,K=6),tmax_seasonal_2$residuals))
grid.arrange(plot1+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()), plot2+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot3+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot4+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()),plot5, ncol=1)
autoplot(forecast(Trial_2_Seasonal,xreg = fourier(training,K=6)[109.5:509.25,])) + my_theme + labs(title = "ARIMA Model", y= "Daily 8 Hour Maximum Ozone Concentration", X= "Date")
# Change this for your computer
# This is the path for the folder where you saved/downloaded the SAS data sets
# for this course from the class webpage. The default folder name was 'Class Data'
file.dir <- "/Users/mukeshravichandran/OneDrive - North Carolina State University/MSA-Mukesh’s MacBook Pro/Courses/Fall/AA502/Fall 1/Time Series/Class Data/"
# Names of the data files from 'Class Data' that we're going to use
input.file1 <- "usairlines.sas7bdat"
# Reads the data at specified directory
# If the file directory is incorrect, then this won't run
USAirlines <- read_sas(paste(file.dir, input.file1,sep = ""))
# Creating Time Series Data Objects
Passenger <- ts(USAirlines$Passengers, start = 1990, frequency = 12)
# Autoregressive Neural Network Model and Forecast
NN.Model <- nnetar(diff(Passenger, 12), p = 2, P = 1, size = 2)
NN.Forecast <- forecast(NN.Model, h = 24)
plot(NN.Forecast)
# Neural Network Model on ARIMA residuals and forecast
xreg1<-cbind(fourier(Passenger,K=5),seq(1,length(Passenger)))
colnames(xreg1)<-c('s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','time')
Model.four<-Arima(Passenger,order=c(0,0,0),xreg=xreg1)
NN.Model2<-nnetar(Model.four$residuals,p=2,P=1,size=2)
NN.Forecast2<-forecast(NN.Model2,h=24)
plot(NN.Forecast2)
# Forecast passengers for next year by adding to previous year's passenger data
Pass.Forecast <- rep(NA, 24)
for(i in 1:12){
Pass.Forecast[i] <- Passenger[length(Passenger) - 12 + i] + forecast(NN.Model, h = 24)$mean[i]
}
# Forecast passengers for next year by adding to the previously forecasted values
for(i in 13:24){
Pass.Forecast[i] <- Pass.Forecast[i - 12] + forecast(NN.Model, h = 24)$mean[i]
}
# Put the forecasted values into a time series object
Pass.Forecast <- ts(Pass.Forecast, start = c(2008, 4), frequency = 12)
# Plot the original (black) and our forecast (blue)
plot(Passenger, main = "US Airline Passengers ARIMA Model Forecasts", xlab = "Date", ylab = "Passengers (Thousands)", xlim = c(1990, 2010), ylim = c(30000,80000))
lines(Pass.Forecast, col = "blue")
abline(v = 2008.25, col = "red", lty = "dashed")
rm(list = ls())
library(haven)
library(forecast)
library(fma)
library(tseries)
library(expsmooth)
library(lmtest)
library(zoo)
library(ggplot2)
library(lubridate)
library(gtable)
library(dplyr)
library(MLmetrics)
library(stinepack)
library(data.table)
library(imputeTS)
library(gridExtra)
setwd("/Users/mukeshravichandran/OneDrive - North Carolina State University/MSA-Mukesh’s MacBook Pro/Courses/Fall/AA502/Fall 1/Time Series/Project/Code/Ozone_Prediction/Data")
my_theme = theme_minimal()+theme(plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill='white')) + theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
#Reading all the project files in
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
#white noise plot
white.noise = function(df) {
White.LB <- rep(NA, 10)
for(i in 1:10){
White.LB[i] <- Box.test(df, lag = i, type = "Lj", fitdf = 1)$p.value
}
White.LBred <- pmin(White.LB, 0.2)
barplot(White.LBred, main = "Ljung-Box Test P-values", ylab = "Probabilities", xlab = "Lags", ylim = c(0, 0.2))
abline(h = 0.01, lty = "dashed", col = "black")
abline(h = 0.05, lty = "dashed", col = "black")
return(White.LB)
}
adf= function(series) {
ADF.Pvalues <- rep(NA, 3)
for(i in 0:2){
ADF.Pvalues[i+1] <- adf.test(series, alternative = "stationary", k = i)$p.value
}
ADF.Pvalues
}
ozone = select(Ozone_Raleigh2.csv,c("Date", "Daily.Max.8.hour.Ozone.Concentration"))
ozone$Date = mdy(ozone$Date)
#Converting in to Date time and imputing missing values
Date <- seq(min(ozone$Date), max(ozone$Date), by = 1)
Date= as.data.frame(Date)
ozone= full_join(Date,ozone,by="Date", suffix=c("",""))
sum(is.na(ozone$Daily.Max.8.hour.Ozone.Concentration)) #60 values missing
ozone$Daily.Max.8.hour.Ozone.Concentration= na_interpolation(ozone$Daily.Max.8.hour.Ozone.Concentration,option = "spline")
sum(is.na(ozone$Daily.Max.8.hour.Ozone.Concentration)) #no values missing
#converting in to time series
ozone_ts= ts(ozone$Daily.Max.8.hour.Ozone.Concentration,start= 2014,frequency = 365.25)
plot1= autoplot(ozone_ts, color= "blue")+my_theme
training= subset(ozone_ts,end=length(ozone_ts)-(28+14))
validation= subset(ozone_ts,start=length(ozone_ts)-(28+14-1), end=length(ozone_ts)-14)
testing= subset(ozone_ts,start=length(ozone_ts)-(13), end=length(ozone_ts))
autoplot(training)+my_theme
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 24)
plot(NN.Forecast)
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 24)
plot(NN.Forecast)
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 200)
plot(NN.Forecast)
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 900)
plot(NN.Forecast)
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 25)
plot(NN.Forecast)
xreg1<-cbind(fourier(training,K=6),seq(1,length(training)))
colnames(xreg1)<-c('s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','s6','c6','time')
View(xreg1)
Model.four<-Arima(training,order=c(0,0,0),xreg=xreg1)
NN.Model2<-nnetar(Model.four$residuals,p=3,size=2)
NN.Forecast2<-forecast(NN.Model2,h=24)
plot(NN.Forecast2)
NN.Forecast2<-forecast(NN.Model2,h=500)
plot(NN.Forecast2)
decompose(training)
plot(decompose(training))
xreg1<-cbind(fourier(training,K=6),seq(1,length(training)))
colnames(xreg1)<-c('s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','s6','c6','time')
Trial_1_Seasonal<-Arima(training,order=c(0,0,0),seasonal=c(0,0,0),xreg=xreg1)
autoplot(Trial_1_Seasonal$residuals,color="red")+ geom_hline(yintercept=0,linetype="dashed")
adf(Trial_1_Seasonal$residuals) # seems like the residuals are stationary
white.noise(Trial_1_Seasonal$residuals) #--> No white noise, so there is some correlation
Acf(Trial_1_Seasonal$residuals,lag.max = 400)$acf
Pacf(Trial_1_Seasonal$residuals,lag.max = 400)$acf
auto.arima(Trial_1_Seasonal$residuals)
Trial_2_Seasonal<-Arima(training,order=c(2,0,0),seasonal=c(0,0,0),xreg=fourier(training,K=6))
Trial_2_Seasonal<-Arima(training,order=c(2,0,0),seasonal=c(0,0,0),xreg=xreg1)
autoplot(Trial_2_Seasonal$residuals,color="red")+ geom_hline(yintercept=0,linetype="dashed") #definitely better than the first one
adf(Trial_2_Seasonal$residuals)
white.noise(Trial_2_Seasonal$residuals) # yaay white noise
summary(Trial_2_Seasonal)
autoplot(forecast(Trial_2_Seasonal,xreg = xreg1[109.5:509.25,])) + my_theme + labs(title = "ARIMA Model", y= "Daily 8 Hour Maximum Ozone Concentration", X= "Date")
NN.Model <- nnetar(training, p = 3, size = 2)
NN.Forecast <- forecast(NN.Model, h = 25)
plot(NN.Forecast)
plot(decompose(training))
Model.four<-Arima(training,order=c(0,0,0),xreg=xreg1)
NN.Model2<-nnetar(Model.four$residuals,p=3,size=2)
NN.Forecast2<-forecast(NN.Model2,h=500)
plot(NN.Forecast2)
Model.four<-Arima(training,order=c(0,0,0),xreg=xreg1)
NN.Model2<-nnetar(Model.four$residuals,p=3,size=2)
NN.Forecast2<-forecast(NN.Model2,h=500)
plot(NN.Forecast2)
# Forecast passengers for next year by adding to previous year's passenger data
Pass.Forecast <- rep(NA, 24)
for(i in 1:12){
Pass.Forecast[i] <- Passenger[length(Passenger) - 12 + i] + forecast(NN.Model, h = 24)$mean[i]
}
# Forecast passengers for next year by adding to the previously forecasted values
for(i in 13:24){
Pass.Forecast[i] <- Pass.Forecast[i - 12] + forecast(NN.Model, h = 24)$mean[i]
}
# Put the forecasted values into a time series object
Pass.Forecast <- ts(Pass.Forecast, start = c(2008, 4), frequency = 12)
# Plot the original (black) and our forecast (blue)
plot(Passenger, main = "US Airline Passengers ARIMA Model Forecasts", xlab = "Date", ylab = "Passengers (Thousands)", xlim = c(1990, 2010), ylim = c(30000,80000))
lines(Pass.Forecast, col = "blue")
abline(v = 2008.25, col = "red", lty = "dashed")
# Add the NN forecasted mean to a fourier time series forecast
for.seq<-seq(220,243)
xreg2<-cbind(fourier(Passenger,K=5,h=24),for.seq)
colnames(xreg2)<-c('s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','time')
Base.forecast<-forecast(Model.four,xreg=xreg2,h=24)
Pass.Forecast2 <- Base.forecast$mean+NN.Forecast2$mean
# Put our second forecast into a time series object
Pass.Forecast2 <- ts(Pass.Forecast2, start = c(2008, 4), frequency = 12)
# Plot the original data (black) and our new forecast (orange)
plot(Passenger, main = "US Airline Passengers ARIMA Model Forecasts", xlab = "Date", ylab = "Passengers (Thousands)", xlim = c(1990, 2010), ylim = c(30000,80000))
lines(Pass.Forecast2, col = "orange")
